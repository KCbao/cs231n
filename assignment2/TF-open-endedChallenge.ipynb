{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF-open-endedChallenge.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPeVm78vL8suDkT2UO5XttC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bifGvHIzWCmr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597986451617,"user_tz":420,"elapsed":2610,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import math\n","import timeit\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiRSSsgJWGVe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1597986606317,"user_tz":420,"elapsed":3908,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}},"outputId":"bb68f5c1-605a-4612-a0e2-dd55287ef460"},"source":["def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n","    \"\"\"\n","    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n","    it for the two-layer neural net classifier. These are the same steps as\n","    we used for the SVM, but condensed to a single function.\n","    \"\"\"\n","    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n","    cifar10 = tf.keras.datasets.cifar10.load_data()\n","    (X_train, y_train), (X_test, y_test) = cifar10\n","    X_train = np.asarray(X_train, dtype=np.float32)\n","    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n","    X_test = np.asarray(X_test, dtype=np.float32)\n","    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n","\n","    # Subsample the data\n","    mask = range(num_training, num_training + num_validation)\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = range(num_training)\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = range(num_test)\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Normalize the data: subtract the mean pixel and divide by std\n","    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n","    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n","    X_train = (X_train - mean_pixel) / std_pixel\n","    X_val = (X_val - mean_pixel) / std_pixel\n","    X_test = (X_test - mean_pixel) / std_pixel\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test\n","\n","# If there are errors with SSL downloading involving self-signed certificates,\n","# it may be that your Python version was recently installed on the current machine.\n","# See: https://github.com/tensorflow/tensorflow/issues/10779\n","# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n","#   ...replacing paths as necessary.\n","\n","# Invoke the above function to get our data.\n","NHW = (0, 1, 2)\n","X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n","print('Train data shape: ', X_train.shape)\n","print('Train labels shape: ', y_train.shape, y_train.dtype)\n","print('Validation data shape: ', X_val.shape)\n","print('Validation labels shape: ', y_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Train data shape:  (49000, 32, 32, 3)\n","Train labels shape:  (49000,) int32\n","Validation data shape:  (1000, 32, 32, 3)\n","Validation labels shape:  (1000,)\n","Test data shape:  (10000, 32, 32, 3)\n","Test labels shape:  (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fx-ROljOWKih","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597986609705,"user_tz":420,"elapsed":886,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}}},"source":["class Dataset(object):\n","    def __init__(self, X, y, batch_size, shuffle=False):\n","        \"\"\"\n","        Construct a Dataset object to iterate over data X and labels y\n","        \n","        Inputs:\n","        - X: Numpy array of data, of any shape\n","        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n","        - batch_size: Integer giving number of elements per minibatch\n","        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n","        \"\"\"\n","        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n","        self.X, self.y = X, y\n","        self.batch_size, self.shuffle = batch_size, shuffle\n","\n","    def __iter__(self):\n","        N, B = self.X.shape[0], self.batch_size\n","        idxs = np.arange(N)\n","        if self.shuffle:\n","            np.random.shuffle(idxs)\n","        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n","\n","\n","train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n","val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n","test_dset = Dataset(X_test, y_test, batch_size=64)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOKMR2t-WO4K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1597986610134,"user_tz":420,"elapsed":790,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}},"outputId":"1be94eaa-e3bf-4b7e-e68e-9fc764f01869"},"source":["# We can iterate through a dataset like this:\n","for t, (x, y) in enumerate(train_dset):\n","    print(t, x.shape, y.shape)\n","    if t > 5: break"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0 (64, 32, 32, 3) (64,)\n","1 (64, 32, 32, 3) (64,)\n","2 (64, 32, 32, 3) (64,)\n","3 (64, 32, 32, 3) (64,)\n","4 (64, 32, 32, 3) (64,)\n","5 (64, 32, 32, 3) (64,)\n","6 (64, 32, 32, 3) (64,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"agb1uWGfWRBL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597986612125,"user_tz":420,"elapsed":856,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}},"outputId":"ff16ad06-8635-499b-b87f-4a96d96aeda9"},"source":["# Set up some global variables\n","USE_GPU = True\n","\n","if USE_GPU:\n","    device = '/device:GPU:0'\n","else:\n","    device = '/cpu:0'\n","\n","# Constant to control how often we print when training models\n","print_every = 100\n","\n","print('Using device: ', device)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using device:  /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kKzF8SUZWTSE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597986614396,"user_tz":420,"elapsed":916,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}}},"source":["def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n","    \"\"\"\n","    Simple training loop for use with models defined using tf.keras. It trains\n","    a model for one epoch on the CIFAR-10 training set and periodically checks\n","    accuracy on the CIFAR-10 validation set.\n","    \n","    Inputs:\n","    - model_init_fn: A function that takes no parameters; when called it\n","      constructs the model we want to train: model = model_init_fn()\n","    - optimizer_init_fn: A function which takes no parameters; when called it\n","      constructs the Optimizer object we will use to optimize the model:\n","      optimizer = optimizer_init_fn()\n","    - num_epochs: The number of epochs to train for\n","    \n","    Returns: Nothing, but prints progress during trainingn\n","    \"\"\"    \n","    with tf.device(device):\n","\n","        # Compute the loss like we did in Part II\n","        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","        \n","        model = model_init_fn()\n","        optimizer = optimizer_init_fn()\n","        \n","        train_loss = tf.keras.metrics.Mean(name='train_loss')\n","        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","    \n","        val_loss = tf.keras.metrics.Mean(name='val_loss')\n","        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n","        \n","        t = 0\n","        for epoch in range(num_epochs):\n","            \n","            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n","            train_loss.reset_states()\n","            train_accuracy.reset_states()\n","            \n","            for x_np, y_np in train_dset:\n","                with tf.GradientTape() as tape:\n","                    \n","                    # Use the model function to build the forward pass.\n","                    scores = model(x_np, training=is_training)\n","                    loss = loss_fn(y_np, scores)\n","      \n","                    gradients = tape.gradient(loss, model.trainable_variables)\n","                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","                    \n","                    # Update the metrics\n","                    train_loss.update_state(loss)\n","                    train_accuracy.update_state(y_np, scores)\n","                    \n","                    if t % print_every == 0:\n","                        val_loss.reset_states()\n","                        val_accuracy.reset_states()\n","                        for test_x, test_y in val_dset:\n","                            # During validation at end of epoch, training set to False\n","                            prediction = model(test_x, training=False)\n","                            t_loss = loss_fn(test_y, prediction)\n","\n","                            val_loss.update_state(t_loss)\n","                            val_accuracy.update_state(test_y, prediction)\n","                        \n","                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n","                        print (template.format(t, epoch+1,\n","                                             train_loss.result(),\n","                                             train_accuracy.result()*100,\n","                                             val_loss.result(),\n","                                             val_accuracy.result()*100))\n","                    t += 1"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxK3TCweWpN8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597987498103,"user_tz":420,"elapsed":1073,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}}},"source":["class CustomConvNet(tf.keras.Model):\n","    def __init__(self):\n","        super(CustomConvNet, self).__init__()\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        num_classes = 10\n","        initializer = tf.initializers.VarianceScaling(scale=2.0)\n","        self.conv1 = tf.keras.layers.Conv2D(32, (3,3), strides = 1, padding='same'\n","                                            ,activation = tf.nn.relu)\n","        self.pool1 = tf.keras.layers.MaxPool2D((2,2))\n","        self.norm1 = tf.keras.layers.BatchNormalization()\n","        self.conv2 = tf.keras.layers.Conv2D(64, (3,3), strides = 1, padding='same',\n","                                            activation = tf.nn.relu)\n","        self.pool2 = tf.keras.layers.MaxPool2D((2,2))\n","        self.norm2 = tf.keras.layers.BatchNormalization()\n","        self.conv3 = tf.keras.layers.Conv2D(256, (3,3), strides = 1, padding='same',\n","                                      activation = tf.nn.relu)\n","        self.pool3 = tf.keras.layers.MaxPool2D((2,2))\n","        self.norm3 = tf.keras.layers.BatchNormalization()\n","        self.conv4 = tf.keras.layers.Conv2D(512, (3,3), strides = 1, padding='same',\n","                                      activation = tf.nn.relu)\n","        self.pool4 = tf.keras.layers.MaxPool2D((2,2))\n","        self.norm4 = tf.keras.layers.BatchNormalization()\n","        self.fc1 = tf.keras.layers.Dense(128, \n","                                       activation = tf.nn.relu)\n","        self.drop1 = tf.keras.layers.Dropout(0.3)\n","        self.normf1 = tf.keras.layers.BatchNormalization()\n","        self.fc2 = tf.keras.layers.Dense(256, \n","                                       activation = tf.nn.relu)\n","        self.drop2 = tf.keras.layers.Dropout(0.3)\n","        self.normf2 = tf.keras.layers.BatchNormalization()\n","        self.fc3 = tf.keras.layers.Dense(512, \n","                       kernel_initializer = initializer,bias_initializer = initializer)\n","        self.fc4 = tf.keras.layers.Dense(256, \n","                      kernel_initializer = initializer,bias_initializer = initializer)\n","                              \n","        self.final = tf.keras.layers.Dense(num_classes, use_bias = True,\n","                      kernel_initializer = initializer,bias_initializer = initializer)\n","                                     \n","       \n","\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","    \n","    def call(self, input_tensor, training=False):\n","        ############################################################################\n","        # TODO: Construct a model that performs well on CIFAR-10                   #\n","        ############################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        x = self.conv1(input_tensor)\n","        x = self.pool1(x)\n","        x = self.norm1(x)\n","        x = self.conv2(x)\n","        x = self.pool2(x)\n","        x = self.norm2(x)        \n","        x = self.conv3(x)\n","        x = self.pool3(x)\n","        x = self.norm3(x)\n","        x = self.conv4(x)\n","        x = self.pool4(x)\n","        x = self.norm4(x)         \n","        x = tf.keras.layers.Flatten()(x)\n","        x = self.fc1(x)\n","        x = self.drop1(x)\n","        x = self.normf1(x)\n","        x = self.fc2(x)\n","        x = self.drop2(x)\n","        x = self.normf2(x)\n","        x = self.fc3(x)\n","        x = self.fc4(x)\n","        x = self.final(x)\n","        \n","       \n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ############################################################################\n","        #                            END OF YOUR CODE                              #\n","        ############################################################################\n","        \n","        return x\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuAM610tWsbE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597987312600,"user_tz":420,"elapsed":229866,"user":{"displayName":"Casie Bao","photoUrl":"","userId":"06476886225701422851"}},"outputId":"3a83702a-453f-4a1b-a68c-f7e986ca5f88"},"source":["device = '/device:GPU:0'\n","learning_rate = 1e-3\n","\n","def model_init_fn():\n","    model = None\n","    model = CustomConvNet()\n","    return model\n","\n","def optimizer_init_fn():\n","    optimizer = None\n","    optimizer = tf.keras.optimizers.Adam(learning_rate) \n","    return optimizer\n","    \n","print_every = 700\n","num_epochs = 10\n","train_part34(model_init_fn, optimizer_init_fn, num_epochs)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Iteration 0, Epoch 1, Loss: 2.3030850887298584, Accuracy: 7.8125, Val Loss: 2.339470863342285, Val Accuracy: 12.300000190734863\n","Iteration 700, Epoch 1, Loss: 1.3052279949188232, Accuracy: 52.2913703918457, Val Loss: 0.9409611821174622, Val Accuracy: 67.0999984741211\n","Iteration 1400, Epoch 2, Loss: 0.7719188332557678, Accuracy: 72.9502944946289, Val Loss: 0.7245126962661743, Val Accuracy: 75.0\n","Iteration 2100, Epoch 3, Loss: 0.5401200652122498, Accuracy: 81.09622192382812, Val Loss: 0.7796425819396973, Val Accuracy: 74.29999542236328\n","Iteration 2800, Epoch 4, Loss: 0.3796386420726776, Accuracy: 86.86319732666016, Val Loss: 0.9057743549346924, Val Accuracy: 75.19999694824219\n","Iteration 3500, Epoch 5, Loss: 0.2777491807937622, Accuracy: 90.27460479736328, Val Loss: 0.863075852394104, Val Accuracy: 74.5\n","Iteration 4200, Epoch 6, Loss: 0.20162758231163025, Accuracy: 92.90347290039062, Val Loss: 0.9895452260971069, Val Accuracy: 75.0999984741211\n","Iteration 4900, Epoch 7, Loss: 0.1633986234664917, Accuracy: 94.5030746459961, Val Loss: 0.9598314762115479, Val Accuracy: 76.5999984741211\n","Iteration 5600, Epoch 8, Loss: 0.13130608201026917, Accuracy: 95.52824401855469, Val Loss: 1.2157707214355469, Val Accuracy: 75.0999984741211\n","Iteration 6300, Epoch 9, Loss: 0.11352461576461792, Accuracy: 96.11632537841797, Val Loss: 1.1508828401565552, Val Accuracy: 75.5999984741211\n","Iteration 7000, Epoch 10, Loss: 0.09690031409263611, Accuracy: 96.88960266113281, Val Loss: 1.0936073064804077, Val Accuracy: 76.80000305175781\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X7ZDwITueGEQ","colab_type":"text"},"source":["## Describe what you did \n","\n","In the cell below you should write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network.\n","\n","Network Architecture: \n","\n","(conv - maxpooling - batchnorm ) * 4 - (fc - maxpooling - batchnorm) * 2 - fc * 3\n","\n","Regularization: Dropout\n","\n","Optimizer: Adam with learning rate 1e-3."]},{"cell_type":"code","metadata":{"id":"ujrCx0Wngg3Z","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}